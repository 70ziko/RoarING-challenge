{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie II: Strażnik Cyberbezpieczeństwa – Ochrona Systemu\n",
    "\n",
    "W tym zadaniu analizuję logi serwera w celu wykrycia potencjalnych ataków hakerskich. Celem jest stworzenie modelu detekcji anomalii, który pozwoli na identyfikację nietypowych zachowań w systemie. W pierwszej kolejności przeprowadzę eksplorację danych, aby zbadać potencjalne cechy i wyczuć co będzie wazne podczas projektowania i trenowania modeli statystycznych jak i sieci neuronowych.\n",
    "\n",
    "## Plan działania\n",
    "\n",
    "1. Eksploracja i wizualizacja danych\n",
    "2. Rozpoznanie podejrzanych wzorców i potencjalnych anomalii\n",
    "3. Opracowanie modelu statystycznego\n",
    "4. Rozdzielenie zestawu danych na treningowy, walidacyjny i testowy, wydzielając anomalie do zbioru testowego\n",
    "5. Feature engineering, preprocessing, etc...\n",
    "6. Opracowanie sieci neuronowej\n",
    "7. Trenowanie oraz walidacja sieci neuronowej\n",
    "8. Test skuteczności na testowym zbiorze danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Eksploracja danych\n",
    "\n",
    "Zacznę od przejrzenia z jakimi danymi mam doczynienia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14945 entries, 0 to 14944\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   date        14945 non-null  object        \n",
      " 1   time        14945 non-null  object        \n",
      " 2   ip          14945 non-null  object        \n",
      " 3   method      14945 non-null  object        \n",
      " 4   path        14945 non-null  object        \n",
      " 5   protocol    14945 non-null  object        \n",
      " 6   status      14945 non-null  int64         \n",
      " 7   referrer    11677 non-null  object        \n",
      " 8   user_agent  14945 non-null  object        \n",
      " 9   payload     5128 non-null   object        \n",
      " 10  timestamp   14945 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(1), object(9)\n",
      "memory usage: 1.3+ MB\n",
      "None\n",
      "\n",
      "Sample of the data:\n",
      "          date      time             ip method        path  protocol  status  \\\n",
      "0  06/Jan/2025  06:02:58  82.81.156.133    GET           /  HTTP/1.1     200   \n",
      "1  06/Jan/2025  06:03:31  82.81.156.133    GET  /logowanie  HTTP/1.1     200   \n",
      "2  06/Jan/2025  06:03:36  82.81.156.133   POST  /logowanie  HTTP/1.1     200   \n",
      "3  06/Jan/2025  06:03:36  82.81.156.133    GET  /dashboard  HTTP/1.1     200   \n",
      "4  06/Jan/2025  06:06:23   81.13.183.39    GET           /  HTTP/1.1     200   \n",
      "\n",
      "                        referrer  \\\n",
      "0                            NaN   \n",
      "1           https://kingbank.pl/   \n",
      "2  https://kingbank.pl/logowanie   \n",
      "3  https://kingbank.pl/logowanie   \n",
      "4                            NaN   \n",
      "\n",
      "                                          user_agent  \\\n",
      "0  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
      "1  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
      "2  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
      "3  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
      "4  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...   \n",
      "\n",
      "                                   payload           timestamp  \n",
      "0                                      NaN 2025-01-06 06:02:58  \n",
      "1                                      NaN 2025-01-06 06:03:31  \n",
      "2  login=tombie3704&password=&action=login 2025-01-06 06:03:36  \n",
      "3                                      NaN 2025-01-06 06:03:36  \n",
      "4                                      NaN 2025-01-06 06:06:23  \n",
      "\n",
      "Tail of the data:\n",
      "              date      time               ip method path  protocol  status  \\\n",
      "14944  16/Jan/2025  16:49:18  185.145.168.192    GET    /  HTTP/1.1     200   \n",
      "\n",
      "      referrer                                         user_agent payload  \\\n",
      "14944      NaN  Mozilla/5.0 (Windows NT 11.0; Win64; x64; rv:1...     NaN   \n",
      "\n",
      "                timestamp  \n",
      "14944 2025-01-16 16:49:18  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-dark')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('data/logs.csv', header=None, \n",
    "                 names=['date', 'time', 'ip', 'method', 'path', 'protocol', \n",
    "                        'status', 'referrer', 'user_agent', 'payload']\n",
    "                 )\n",
    "\n",
    "# Combine date and time into a datetime column\n",
    "df['timestamp'] = pd.to_datetime(df['date'] + ' ' + df['time'], \n",
    "                               format='%d/%b/%Y %H:%M:%S')\n",
    "\n",
    "# Basic info about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nSample of the data:\")\n",
    "print(df.head())\n",
    "print(\"\\nTail of the data:\")\n",
    "print(df.tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charakterystyka danych\n",
    "\n",
    "Mamy doczynienia z zrzutem 14945 logów sieciowych serwera `kingbank.pl` na przełomie 10 dni. Jest to niewielka liczba danych. Jak na logi aplikacji są całkiem nieźle ustruktyryzowane i zostały juz prawdopodbnie początkowo wyabstraktowane. \n",
    "\n",
    "1. Ruch sieciowy składa się jedynie z ruchu **HTTP**\n",
    "2. Są to logi poszczególnych punktów końcowych API na serwerze hostującym stronę kingbank.pl\n",
    "3. Liczba wierszy: **14945**\n",
    "4. Okres czasowy: **06.01.2025 - 16.01.2025**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values for each column:\n",
      "date             11\n",
      "time          10002\n",
      "ip             2194\n",
      "method            2\n",
      "path           1004\n",
      "protocol          1\n",
      "status            5\n",
      "referrer        958\n",
      "user_agent       30\n",
      "payload        3014\n",
      "timestamp     10869\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count unique values for each column\n",
    "print(\"\\nUnique values for each column:\")\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dzięki liście unikalnych wartości widzimy: \n",
    "\n",
    "- większość wartości dla payload jest unikalna (3014/5128). \n",
    "- Protokół jest tylko jeden: HTTP, nie istotny jako cecha dla modeli. \n",
    "- Wyjątkowo mało jest unikalnych user_agent. (mozliwe ze bottom user-agent pokaze coś ciekawego)\n",
    "- Unikalnych IP jest ~1/7 (2194/14945) zbioru danych. Sugeruje, ze sesje nie trwały długo\n",
    "- Ciekawe jest, ze unikalnych znaczników czasowych jest tylko 2/3 zbioru danych, mozliwe ataki siłowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przydatne wizualizacje danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with multiple subplots\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# 1. Request Methods Distribution\n",
    "plt.subplot(2, 2, 1)\n",
    "method_counts = df['method'].value_counts()\n",
    "sns.barplot(x=method_counts.index, y=method_counts.values)\n",
    "plt.title('Distribution of HTTP Methods')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 2. Status Codes Distribution\n",
    "plt.subplot(2, 2, 2)\n",
    "status_counts = df['status'].value_counts()\n",
    "sns.barplot(x=status_counts.index, y=status_counts.values)\n",
    "plt.title('Distribution of HTTP Status Codes')\n",
    "\n",
    "# 3. Requests Over Time\n",
    "plt.subplot(2, 2, 3)\n",
    "df.set_index('timestamp').resample('1H')['method'].count().plot()\n",
    "plt.title('Number of Requests per Hour')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Number of Requests')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# 4. Top 10 Most Requested Paths\n",
    "plt.subplot(2, 2, 4)\n",
    "path_counts = df['path'].value_counts().head(10)\n",
    "sns.barplot(x=path_counts.values, y=path_counts.index)\n",
    "plt.title('Top 10 Most Requested Paths')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nTop 10 IP addresses by number of requests:\")\n",
    "print(df['ip'].value_counts().head(10))\n",
    "\n",
    "print(\"\\nTop 10 paths with their request counts:\")\n",
    "print(df['path'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wnioski na temat powyzszych wizualizacji i statystyk\n",
    "\n",
    "Jak widać nie ma zadnego adresu IP, który miałby nienaturalnie duzą liczbę zapytań. \n",
    "\n",
    "Natomiast na pewno punkt końcowy /logowanie ma nienaturalnie duzą liczbę uderzeń, większą niz strona główna aplikacji, jest to ewidentnie nienaturalne zachowanie, a nawet potencjalny atak. Zobaczmy dokładniej jak wyglądają wzorce zapytań i czy mozna znaleźć podejrzane zachowania.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Security Analysis Summary:\n",
      "Total number of login attempts: 4087\n",
      "Number of unique IPs making login attempts: 2023\n",
      "Number of rapid request incidents: 3\n",
      "Number of suspicious payloads detected: 3\n",
      "Number of unusual paths accessed: 0\n",
      "\n",
      "Sequential Login Attempts Analysis:\n",
      "IP: 178.144.125.23\n",
      "Total login attempts: 10\n",
      "Timespan: 0 days 00:00:57\n",
      "--------------------------------------------------\n",
      "IP: 83.9.37.128\n",
      "Total login attempts: 18\n",
      "Timespan: 0 days 00:01:03\n",
      "--------------------------------------------------\n",
      "\n",
      "Path patterns for suspicious IPs:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Function to detect potential suspicious patterns based, author: claude.ai, editor: 70ziko\n",
    "def analyze_suspicious_patterns(df):\n",
    "    suspicious_patterns = {\n",
    "        'rapid_requests': [],\n",
    "        'login_attempts': [],\n",
    "        'suspicious_payloads': [],\n",
    "        'unusual_paths': []\n",
    "    }\n",
    "    \n",
    "    # 1. Detect rapid requests from same IP (more than 10 requests per minute)\n",
    "    ip_time_groups = df.groupby([df['ip'], \n",
    "                                df['timestamp'].dt.floor('min')])['method'].count()\n",
    "    rapid_requests = ip_time_groups[ip_time_groups > 7]\n",
    "    \n",
    "    # 2. Analyze login attempts - specifically looking at failed login patterns\n",
    "    login_attempts = df[df['path'].str.contains('/logowanie', na=False)]\n",
    "    failed_logins = login_attempts[\n",
    "        login_attempts['status'] // 100 >= 4]\n",
    "    \n",
    "    # 3. Look for suspicious payloads - using safe pattern matching\n",
    "    suspicious_patterns = [\n",
    "        r'script\\W*', r'eval\\s*\\(', r'exec\\s*\\(', r'SELECT\\s+\\w+', \n",
    "        r'UNION\\s+SELECT', r'DROP\\s+TABLE', r'alert\\s*\\(', \n",
    "        r'<[^>]*script'\n",
    "    ]\n",
    "    pattern = '|'.join(suspicious_patterns)\n",
    "    suspicious_payloads = df[\n",
    "        df['payload'].str.contains(pattern, na=False, case=False, regex=True)]\n",
    "    \n",
    "    # 4. Detect unusual paths\n",
    "    unusual_path_patterns = [\n",
    "        r'\\.\\.//', r'%00', r'/etc/passwd', r'/wp-admin',\n",
    "        r'\\.php$', r'\\.asp$', r'\\.exe$', r'\\.dll$'\n",
    "    ]\n",
    "    pattern = '|'.join(unusual_path_patterns)\n",
    "    unusual_paths = df[\n",
    "        (df['path'].str.len() > 100) | \n",
    "        (df['path'].str.contains(pattern, na=False, case=False, regex=True))]\n",
    "    \n",
    "    # Additional analysis - Looking for sequential failed login attempts\n",
    "    sequential_login_attempts = []\n",
    "    for ip in df['ip'].unique():\n",
    "        ip_logins = login_attempts[login_attempts['ip'] == ip]\n",
    "        if len(ip_logins) > 5:  # More than 5 login attempts from same IP\n",
    "            sequential_login_attempts.append({\n",
    "                'ip': ip,\n",
    "                'count': len(ip_logins),\n",
    "                'timespan': ip_logins['timestamp'].max() - ip_logins['timestamp'].min()\n",
    "            })\n",
    "    \n",
    "    return {\n",
    "        'rapid_requests': rapid_requests,\n",
    "        'login_attempts': failed_logins,\n",
    "        'suspicious_payloads': suspicious_payloads,\n",
    "        'unusual_paths': unusual_paths,\n",
    "        'sequential_logins': sequential_login_attempts\n",
    "    }\n",
    "\n",
    "# Analyze suspicious patterns\n",
    "suspicious_patterns = analyze_suspicious_patterns(df)\n",
    "\n",
    "# Create visualization for the analysis\n",
    "# plt.figure(figsize=(20, 12))\n",
    "\n",
    "# # 1. Plot login attempts over time\n",
    "# plt.subplot(2, 2, 1)\n",
    "# login_attempts = df[df['path'] == '/logowanie']\n",
    "# login_attempts.set_index('timestamp')['ip'].resample('1H').count().plot()\n",
    "# plt.title('Login Attempts Over Time')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('Number of Attempts')\n",
    "\n",
    "# # 2. Plot unique IPs making login attempts\n",
    "# plt.subplot(2, 2, 2)\n",
    "# top_login_ips = login_attempts['ip'].value_counts().head(10)\n",
    "# sns.barplot(x=top_login_ips.values, y=top_login_ips.index)\n",
    "# plt.title('Top 10 IPs by Login Attempts')\n",
    "# plt.xlabel('Number of Attempts')\n",
    "\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# Print summary statistics and findings\n",
    "print(\"\\nSecurity Analysis Summary:\")\n",
    "print(f\"Total number of login attempts: {len(login_attempts)}\")\n",
    "print(f\"Number of unique IPs making login attempts: {login_attempts['ip'].nunique()}\")\n",
    "print(f\"Number of rapid request incidents: {len(suspicious_patterns['rapid_requests'])}\")\n",
    "print(f\"Number of suspicious payloads detected: {len(suspicious_patterns['suspicious_payloads'])}\")\n",
    "print(f\"Number of unusual paths accessed: {len(suspicious_patterns['unusual_paths'])}\")\n",
    "\n",
    "# Print details of sequential login attempts\n",
    "print(\"\\nSequential Login Attempts Analysis:\")\n",
    "for attempt in suspicious_patterns['sequential_logins']:\n",
    "    print(f\"IP: {attempt['ip']}\")\n",
    "    print(f\"Total login attempts: {attempt['count']}\")\n",
    "    print(f\"Timespan: {attempt['timespan']}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Additional analysis of paths accessed by suspicious IPs\n",
    "suspicious_ips = set(suspicious_patterns['rapid_requests'].index)\n",
    "if suspicious_ips:\n",
    "    print(\"\\nPath patterns for suspicious IPs:\")\n",
    "    suspicious_ip_paths = df[df['ip'].isin(suspicious_ips)]['path'].value_counts()\n",
    "    print(suspicious_ip_paths.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 User-Agents:\n",
      "user_agent\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36           4435\n",
      "Mozilla/5.0 (Windows NT 11.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0                                          1615\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:129.0) Gecko/20100101 Firefox/129.0                                          1574\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0                                          1510\n",
      "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36                      430\n",
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 11_0_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36       418\n",
      "Mozilla/5.0 (Windows NT 10.0; WOW64; rv:128.0) Gecko/20100101 Firefox/128.0                                                414\n",
      "Mozilla/5.0 (Linux; Android 13; SM-G990B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Mobile Safari/537.36     404\n",
      "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:130.0) Gecko/20100101 Firefox/130.0                                             397\n",
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 13_0_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36       378\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Przykłady podejrzanych payloadów:\n",
      "4414    login=test'; DROP TABLE users;--&password=&act...\n",
      "4415    login=marpow4372' UNION SELECT username, passw...\n",
      "4421    login=marpow43721' UNION SELECT null, username...\n",
      "Name: payload, dtype: object\n",
      "\n",
      "Rozkład kodów statusu dla /logowanie:\n",
      "status\n",
      "200    3986\n",
      "400      91\n",
      "401       5\n",
      "403       5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Analiza User-Agent\n",
    "print(\"\\nTop 10 User-Agents:\")\n",
    "print(df['user_agent'].value_counts().head(10))\n",
    "\n",
    "# Analiza podejrzanych payloadów\n",
    "print(\"\\nPrzykłady podejrzanych payloadów:\")\n",
    "if len(suspicious_patterns['suspicious_payloads']) > 0:\n",
    "    print(suspicious_patterns['suspicious_payloads']['payload'].head())\n",
    "else:\n",
    "    print(\"Nie znaleziono podejrzanych payloadów\")\n",
    "\n",
    "# Analiza statusów HTTP dla endpointu /logowanie\n",
    "login_status = df[df['path'] == '/logowanie']['status'].value_counts()\n",
    "print(\"\\nRozkład kodów statusu dla /logowanie:\")\n",
    "print(login_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Szczegółowa analiza anomalii i ataków\n",
    "\n",
    "Na podstawie przeprowadzonej analizy zidentyfikowano następujące typy ataków i anomalii:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SQL Injection Attacks:\n",
      "--------------------------------------------------------------------------------\n",
      "Attacker IP: 178.144.125.23\n",
      "Number of attempts: 6\n",
      "Time range: 2025-01-09 09:23:04 to 2025-01-09 09:23:58\n",
      "Example payloads:\n",
      "  - login=marpow4372' OR 'x'='x' LIMIT 1;--&password=&action=login\n",
      "  - login=test'; DROP TABLE users;--&password=&action=login\n",
      "  - login=marpow4372' UNION SELECT username, password FROM accounts WHERE '1'='1&password=&action=login\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Brute Force Attacks:\n",
      "--------------------------------------------------------------------------------\n",
      "Attacker IP: 178.144.125.23\n",
      "Number of attempts: 10\n",
      "Time range: 2025-01-09 09:23:01 to 2025-01-09 09:23:58\n",
      "Targeted users: admin, marpow4372, test, marpow4372&password=&action=login, marpow43721\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def analyze_sql_injection_attempts(df):\n",
    "    # SQL injection patterns\n",
    "    sql_patterns = [\n",
    "        r'UNION\\s+SELECT',\n",
    "        r'SELECT\\s+.*\\s+FROM',\n",
    "        r'DROP\\s+TABLE',\n",
    "        r'--\\s*$',\n",
    "        r';\\s*--',\n",
    "        r'OR\\s+1=1',\n",
    "        r'SLEEP\\s*\\(',\n",
    "        r'WAITFOR\\s+DELAY',\n",
    "        r'BENCHMARK\\s*\\('\n",
    "    ]\n",
    "    \n",
    "    pattern = '|'.join(sql_patterns)\n",
    "    sql_injection_attempts = df[df['payload'].str.contains(pattern, na=False, case=False, regex=True)]\n",
    "    \n",
    "    if len(sql_injection_attempts) > 0:\n",
    "        # Group by IP and get time ranges\n",
    "        sql_attacks = []\n",
    "        for ip in sql_injection_attempts['ip'].unique():\n",
    "            ip_attempts = sql_injection_attempts[sql_injection_attempts['ip'] == ip]\n",
    "            sql_attacks.append({\n",
    "                'ip': ip,\n",
    "                'count': len(ip_attempts),\n",
    "                'start_time': ip_attempts['timestamp'].min(),\n",
    "                'end_time': ip_attempts['timestamp'].max(),\n",
    "                'example_payloads': ip_attempts['payload'].head(3).tolist()\n",
    "            })\n",
    "        \n",
    "        return sql_attacks\n",
    "    \n",
    "    return []\n",
    "\n",
    "def analyze_brute_force_attempts(df):\n",
    "    login_attempts = df[df['path'].str.contains('/logowanie', na=False)]\n",
    "    failed_logins = login_attempts[login_attempts['status'] // 100 >= 4]\n",
    "    \n",
    "    brute_force_attacks = []\n",
    "    for ip in failed_logins['ip'].unique():\n",
    "        ip_attempts = failed_logins[failed_logins['ip'] == ip]\n",
    "        if len(ip_attempts) >= 5:  # Consider it brute force if 5 or more failed attempts\n",
    "            brute_force_attacks.append({\n",
    "                'ip': ip,\n",
    "                'count': len(ip_attempts),\n",
    "                'start_time': ip_attempts['timestamp'].min(),\n",
    "                'end_time': ip_attempts['timestamp'].max(),\n",
    "                'affected_users': ip_attempts['payload'].str.extract(r'login[\"\\']?\\s*[:=]\\s*[\"\\']?([^\"\\',\\s]+)', expand=False).dropna().unique().tolist()\n",
    "            })\n",
    "    \n",
    "    return brute_force_attacks\n",
    "\n",
    "# Analyze SQL injection attempts\n",
    "sql_attacks = analyze_sql_injection_attempts(df)\n",
    "print(\"\\nSQL Injection Attacks:\")\n",
    "print(\"-\" * 80)\n",
    "for attack in sql_attacks:\n",
    "    print(f\"Attacker IP: {attack['ip']}\")\n",
    "    print(f\"Number of attempts: {attack['count']}\")\n",
    "    print(f\"Time range: {attack['start_time']} to {attack['end_time']}\")\n",
    "    print(\"Example payloads:\")\n",
    "    for payload in attack['example_payloads']:\n",
    "        print(f\"  - {payload}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Analyze brute force attempts\n",
    "brute_force_attacks = analyze_brute_force_attempts(df)\n",
    "print(\"\\nBrute Force Attacks:\")\n",
    "print(\"-\" * 80)\n",
    "for attack in brute_force_attacks:\n",
    "    print(f\"Attacker IP: {attack['ip']}\")\n",
    "    print(f\"Number of attempts: {attack['count']}\")\n",
    "    print(f\"Time range: {attack['start_time']} to {attack['end_time']}\")\n",
    "    if attack['affected_users']:\n",
    "        print(f\"Targeted users: {', '.join(attack['affected_users'])}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Anomaly Statistics:\n",
      "Total records: 14945\n",
      "Anomalous records: 10\n",
      "Percentage of anomalous data: 0.07%\n",
      "\n",
      "After including additional suspicious behavior:\n",
      "Anomalous records: 72\n",
      "Percentage of anomalous data: 0.48%\n"
     ]
    }
   ],
   "source": [
    "def identify_anomalous_data(df, sql_attacks, brute_force_attacks):\n",
    "    # Collect all suspicious IPs\n",
    "    suspicious_ips = set(\n",
    "        [attack['ip'] for attack in sql_attacks] +\n",
    "        [attack['ip'] for attack in brute_force_attacks]\n",
    "    )\n",
    "    \n",
    "    # Get time ranges for anomalous activity\n",
    "    anomaly_periods = []\n",
    "    for attack in sql_attacks + brute_force_attacks:\n",
    "        anomaly_periods.append({\n",
    "            'start': attack['start_time'],\n",
    "            'end': attack['end_time']\n",
    "        })\n",
    "    \n",
    "    # Mark records as anomalous if they're from suspicious IPs or within anomaly periods\n",
    "    df['is_anomalous'] = False\n",
    "    \n",
    "    # Mark by suspicious IPs\n",
    "    df.loc[df['ip'].isin(suspicious_ips), 'is_anomalous'] = True\n",
    "    \n",
    "    # Mark by time periods\n",
    "    for period in anomaly_periods:\n",
    "        mask = (df['timestamp'] >= period['start']) & (df['timestamp'] <= period['end'])\n",
    "        df.loc[mask, 'is_anomalous'] = True\n",
    "    \n",
    "    # Calculate percentage of anomalous data\n",
    "    anomaly_percentage = (df['is_anomalous'].sum() / len(df)) * 100\n",
    "    \n",
    "    print(f\"\\nAnomaly Statistics:\")\n",
    "    print(f\"Total records: {len(df)}\")\n",
    "    print(f\"Anomalous records: {df['is_anomalous'].sum()}\")\n",
    "    print(f\"Percentage of anomalous data: {anomaly_percentage:.2f}%\")\n",
    "    \n",
    "    # If less than 20% is anomalous, include additional suspicious behavior\n",
    "    if anomaly_percentage < 20:\n",
    "        # Include rapid requests\n",
    "        ip_time_groups = df.groupby([df['ip'], df['timestamp'].dt.floor('min')])['method'].count()\n",
    "        rapid_request_ips = ip_time_groups[ip_time_groups > 7].index.get_level_values(0)\n",
    "        df.loc[df['ip'].isin(rapid_request_ips), 'is_anomalous'] = True\n",
    "        \n",
    "        # Include suspicious user agents\n",
    "        suspicious_agents = df['user_agent'].value_counts()[df['user_agent'].value_counts() < 5].index\n",
    "        df.loc[df['user_agent'].isin(suspicious_agents), 'is_anomalous'] = True\n",
    "        \n",
    "        # Recalculate percentage\n",
    "        anomaly_percentage = (df['is_anomalous'].sum() / len(df)) * 100\n",
    "        print(f\"\\nAfter including additional suspicious behavior:\")\n",
    "        print(f\"Anomalous records: {df['is_anomalous'].sum()}\")\n",
    "        print(f\"Percentage of anomalous data: {anomaly_percentage:.2f}%\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Identify anomalous data\n",
    "df_with_anomalies = identify_anomalous_data(df, sql_attacks, brute_force_attacks)\n",
    "\n",
    "# Show distribution of anomalies over time\n",
    "# plt.figure(figsize=(15, 6))\n",
    "# df_with_anomalies.set_index('timestamp').resample('1H')['is_anomalous'].mean().plot()\n",
    "# plt.title('Anomaly Distribution Over Time')\n",
    "# plt.xlabel('Time')\n",
    "# plt.ylabel('Proportion of Anomalous Traffic')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalous Activity:\n",
      "              date      time              ip method path  protocol  status  \\\n",
      "1522   07/Jan/2025  00:24:57   82.84.217.223    GET    /  HTTP/1.1     200   \n",
      "1953   07/Jan/2025  11:11:33    82.139.39.57    GET    /  HTTP/1.1     200   \n",
      "2012   07/Jan/2025  11:50:12   82.212.93.186    GET    /  HTTP/1.1     200   \n",
      "2798   08/Jan/2025  05:00:19  82.120.247.227    GET    /  HTTP/1.1     200   \n",
      "3952   08/Jan/2025  20:03:07  82.155.213.224    GET    /  HTTP/1.1     200   \n",
      "...            ...       ...             ...    ...  ...       ...     ...   \n",
      "12414  15/Jan/2025  00:23:27    82.33.221.12    GET    /  HTTP/1.1     200   \n",
      "12597  15/Jan/2025  07:59:20  185.95.199.120    GET    /  HTTP/1.1     200   \n",
      "13512  15/Jan/2025  16:20:16    81.43.161.77    GET    /  HTTP/1.1     200   \n",
      "13811  15/Jan/2025  20:54:20    81.59.150.62    GET    /  HTTP/1.1     200   \n",
      "14743  16/Jan/2025  14:41:45     81.82.57.31    GET    /  HTTP/1.1     200   \n",
      "\n",
      "      referrer                                         user_agent payload  \\\n",
      "1522       NaN  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...     NaN   \n",
      "1953       NaN  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...     NaN   \n",
      "2012       NaN     Bingbot/2.0 (+http://www.bing.com/bingbot.htm)     NaN   \n",
      "2798       NaN  Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/53...     NaN   \n",
      "3952       NaN                                        curl/7.78.0     NaN   \n",
      "...        ...                                                ...     ...   \n",
      "12414      NaN  Mozilla/5.0 (Windows NT 10.0; Win64; x64) Appl...     NaN   \n",
      "12597      NaN                            Wget/1.21.3 (linux-gnu)     NaN   \n",
      "13512      NaN  facebookexternalhit/1.1 (+http://www.facebook....     NaN   \n",
      "13811      NaN  Mozilla/5.0 (compatible; YandexBot/3.0; +http:...     NaN   \n",
      "14743      NaN                                        curl/7.78.0     NaN   \n",
      "\n",
      "                timestamp  is_anomalous  \n",
      "1522  2025-01-07 00:24:57          True  \n",
      "1953  2025-01-07 11:11:33          True  \n",
      "2012  2025-01-07 11:50:12          True  \n",
      "2798  2025-01-08 05:00:19          True  \n",
      "3952  2025-01-08 20:03:07          True  \n",
      "...                   ...           ...  \n",
      "12414 2025-01-15 00:23:27          True  \n",
      "12597 2025-01-15 07:59:20          True  \n",
      "13512 2025-01-15 16:20:16          True  \n",
      "13811 2025-01-15 20:54:20          True  \n",
      "14743 2025-01-16 14:41:45          True  \n",
      "\n",
      "[72 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the anomalous activity from the dataset\n",
    "anomalous_activity = df_with_anomalies[df_with_anomalies['is_anomalous']]\n",
    "print(\"Anomalous Activity:\")\n",
    "print(anomalous_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podsumowanie analizy anomalii\n",
    "\n",
    "Na podstawie powyzszej analizy zidentyfikowano następujące typy ataków i anomalii:\n",
    "\n",
    "1. **SQL Injection Attacks**:\n",
    "   - Próby wstrzyknięcia złośliwego kodu SQL\n",
    "   - Szczegóły dla każdego atakującego IP zostały wyświetlone powyżej\n",
    "   - Zawierają dokładne przedziały czasowe i przykładowe payloady\n",
    "\n",
    "2. **Brute Force Attacks**:\n",
    "   - Próby zgadnięcia hasła poprzez wielokrotne próby logowania\n",
    "   - Dla każdego atakującego IP pokazano:\n",
    "     * Liczbę prób\n",
    "     * Dokładny przedział czasowy\n",
    "     * Zaatakowane konta użytkowników\n",
    "\n",
    "3. **Dodatkowe anomalie**:\n",
    "   - Podejrzane wzorce ruchu (ponad 7 requestów na minutę)\n",
    "   - Nietypowe User-Agent strings\n",
    "   - Nienaturalne wzorce dostępu do endpointów\n",
    "\n",
    "## Rekomendowany podział danych\n",
    "\n",
    "Bazując na przeprowadzonej analizie, zidentyfikowano około 72 nietypowych zapytań, czyli ok. 0.48% przechwyconego ruchu sieciowego, najwięcej anomalii nastąpiło w dniach 8.01 oraz 14.01. \n",
    "\n",
    "### Podział danych ze względu na architekturę modelu AI\n",
    "\n",
    "Jako detektor anomalii wytrenuję model LSTM-RNN, który dzięki wykorzystaniu ukrytych stanów, sekwencyjnie analizuje dane biorąc pod uwagę poprzednie wejścia. \n",
    "\n",
    "Model zostanie nauczony wzorców normalnego ruchu w paradygmacie self-supervised learning. W tym celu najlepsze wyniki uzyskam, poprzez oddzielenie ruchu z anomaliami od typowego ruchu sieciowego. \n",
    " \n",
    "- 80% - zbiór treningow oraz walidacyjny\n",
    "   - 80% * 88% = 70,4% : zbiór testowy\n",
    "   - 80% * 12% = 9,6% : zbiór walidacyjny\n",
    "- 20% - zbiór testowy zawierający większość ruchu z anomaliami\n",
    "   \n",
    "W celu wybrania ruchu z największą ilością anomalii wybrałem 2 dni, które mają największą proporcję podejrzanego ruchu do ruchu normalnego. Wybrane dni to: 08.01.2025 oraz 14.01.2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trenowanie modelu\n",
    "W folderze RNN znajdują się definicje modelu LSTM-RNN, wytrenowane wagi oraz skrypt do uruchamiania modelu dla nowych danych.\n",
    "\n",
    "## Proces trenowania\n",
    "Przed przystąpieniem do trenowania nalezy rozdzielić zbiór danych na treningowy oraz testowy. Jak widać w folderze RNN/weights znajdują się takze wagi modelu trenowanego na całości danych (80% train / 20% val)\n",
    "\n",
    "### Podział danych\n",
    "Zgodnie z powyzszą analizą wybrałem dni 8 i 14 stycznia jako testowe, gdyz są najbardziej podejrzane. W tym celu mozna uzyć skryptu `scripts/split_data.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split files already exist in data/splits\n"
     ]
    }
   ],
   "source": [
    "!python scripts/split_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trenowanie modelu\n",
    "Plik `RNN/train.py`posiada zarówno definicję modelu, jak i proces trenowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/70ziko/projekty/RoarING/solutions/2/RNN/train.py\", line 3, in <module>\n",
      "    import torch\n",
      "ModuleNotFoundError: No module named 'torch'\n"
     ]
    }
   ],
   "source": [
    "!python RNN/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testowanie na nowych danych (lub oddzielonych)\n",
    "W tym celu mozna uzyć skryptu `RNN/inference.py`, który zapisze wyniki w `RNN/anomaly_detection_results.csv`. Podsumowanie zostanie wyświetlone w stdout:\n",
    "```bash\n",
    "Summary:\n",
    "--------------------------------------------------\n",
    "Detected 130 anomalies in 2603 logs\n",
    "Anomaly threshold: 1.9764\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/70ziko/projekty/RoarING/solutions/2/RNN/inference.py\", line 1, in <module>\n",
      "    import torch\n",
      "ModuleNotFoundError: No module named 'torch'\n"
     ]
    }
   ],
   "source": [
    "!python RNN/inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analiza predykcji\n",
    "Statystyki i podgląd predykcji mozna wygenerować uywając skryptu: `scripts/analyze_results.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Anomaly Detection Summary ===\n",
      "Total logs analyzed: 2,603\n",
      "Total anomalies detected: 130 (5.0% of logs)\n",
      "Average anomaly score: 0.6475\n",
      "Anomaly score threshold: 1.9802\n",
      "\n",
      "=== Temporal Distribution ===\n",
      "Peak anomaly hour: 12:00 (16 anomalies)\n",
      "\n",
      "=== IP Address Analysis ===\n",
      "Top 5 IPs with most anomalies:\n",
      "  81.221.120.178: 2 anomalies\n",
      "  81.246.224.238: 2 anomalies\n",
      "  81.214.169.226: 2 anomalies\n",
      "  82.143.172.44: 2 anomalies\n",
      "  82.141.153.154: 2 anomalies\n",
      "\n",
      "=== Endpoint Analysis ===\n",
      "Most attacked endpoints:\n",
      "  /wylogowanie: 79 anomalies\n",
      "  /transakcja: 29 anomalies\n",
      "  /logowanie: 20 anomalies\n",
      "  /: 1 anomalies\n",
      "  /rejestracja: 1 anomalies\n",
      "\n",
      "=== Sample Anomalies ===\n",
      "Top 3 anomalies by score:\n",
      "--------------------------------------------------------------------------------\n",
      "Time: 08/Jan/2025 15:02:02\n",
      "IP: 81.246.224.238\n",
      "Request: POST /logowanie\n",
      "Status: 400\n",
      "Payload: login=adaro6794&password=&action=login\n",
      "Anomaly Score: 5.1001\n",
      "--------------------------------------------------------------------------------\n",
      "Time: 14/Jan/2025 13:08:29\n",
      "IP: 82.239.15.165\n",
      "Request: POST /rejestracja\n",
      "Status: 400\n",
      "Payload: firstName=Patryk&lastName=Mazurek&email=patryk.mazurek38dark471@interia.pl&password=&confirmPassword=&action=register\n",
      "Anomaly Score: 4.7878\n",
      "--------------------------------------------------------------------------------\n",
      "Time: 08/Jan/2025 15:01:59\n",
      "IP: 81.246.224.238\n",
      "Request: POST /logowanie\n",
      "Status: 400\n",
      "Payload: login=adaro6794&password=&action=login\n",
      "Anomaly Score: 4.6659\n",
      "\n",
      "=== Payload Analysis ===\n",
      "Number of anomalies with payloads: 129\n",
      "\n",
      "Sample suspicious payloads:\n",
      "- action=logout\n",
      "- recipientAccount=75+8355+1048+2385+7890+1624+6845&recipientName=Karolina+Tymowski&street=ul.+Zaciszna&houseNumber=43&apartmentNumber=24&postalCode=11795&city=Weso%C5%82owo&transferTitle=Na+zakupy+spo%C5%BCywcze&action=send&savedRecipient=1\n",
      "- recipientAccount=97+8817+1010+9595+5548+0858+2750&recipientName=FineDesign+Studio&street=ul.+Ogrodowa&houseNumber=85&apartmentNumber=32&postalCode=65023&city=Zielonka&transferTitle=Zakup+produkt%C3%B3w+promocyjnych&action=send&savedRecipient=1\n",
      "\n",
      "=== Status Code Distribution in Anomalies ===\n",
      "  Status 302: 79 occurrences (60.8%)\n",
      "  Status 200: 30 occurrences (23.1%)\n",
      "  Status 400: 21 occurrences (16.2%)\n"
     ]
    }
   ],
   "source": [
    "!python scripts/analyze_results.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
